{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**importing packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "from glob import glob\n",
    "import os\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dawnloading data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data downloaded\n"
     ]
    }
   ],
   "source": [
    "dataset = fo.zoo.load_zoo_dataset(\n",
    "              \"open-images-v7\",\n",
    "              split=\"train\",\n",
    "              label_types=[\"segmentations\"],\n",
    "              classes=[\"Car\"],\n",
    "              max_samples=15000,\n",
    "          )\n",
    "print('data downloaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100% |█████████████| 15003/15003 [26.7m elapsed, 0s remaining, 7.3 samples/s]      \n"
     ]
    }
   ],
   "source": [
    "# The directory containing the dataset to import\n",
    "dataset_dir = r\"C:\\Users\\Tarek\\fiftyone\\open-images-v7\\train\"\n",
    "\n",
    "# The type of the dataset being imported\n",
    "dataset_type = fo.types.dataset_types.OpenImagesV7Dataset  # for example\n",
    "\n",
    "# Import the dataset\n",
    "dataset = fo.Dataset.from_dir(\n",
    "    dataset_dir=dataset_dir,\n",
    "    dataset_type=dataset_type,\n",
    "    label_types=[\"segmentations\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**getting labels for downloaded images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_id_from_image_path(path):\n",
    "    id = path.split('\\\\')[-1][0:16]\n",
    "    return id\n",
    "def extract_id_from_mask(path):\n",
    "    mask_id  = path.split('\\\\')[-1]\n",
    "    return mask_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = r'C:\\Users\\Tarek\\fiftyone\\open-images-v7\\train'\n",
    "images_path = glob(os.path.join(ROOT_DIR,'data')+'/*')\n",
    "#images_path = images_path[40:60]\n",
    "image_ids = [extract_id_from_image_path(path) for path in images_path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a6ee282596c42e491133704acad12d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "printing folders:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on the  1th folder and folder path is :C:\\Users\\Tarek\\fiftyone\\open-images-v7\\train\\labels\\masks\\0\n",
      "working on the  2th folder and folder path is :C:\\Users\\Tarek\\fiftyone\\open-images-v7\\train\\labels\\masks\\1\n",
      "working on the  3th folder and folder path is :C:\\Users\\Tarek\\fiftyone\\open-images-v7\\train\\labels\\masks\\2\n",
      "working on the  4th folder and folder path is :C:\\Users\\Tarek\\fiftyone\\open-images-v7\\train\\labels\\masks\\3\n",
      "working on the  5th folder and folder path is :C:\\Users\\Tarek\\fiftyone\\open-images-v7\\train\\labels\\masks\\4\n",
      "working on the  6th folder and folder path is :C:\\Users\\Tarek\\fiftyone\\open-images-v7\\train\\labels\\masks\\5\n",
      "working on the  7th folder and folder path is :C:\\Users\\Tarek\\fiftyone\\open-images-v7\\train\\labels\\masks\\6\n",
      "working on the  8th folder and folder path is :C:\\Users\\Tarek\\fiftyone\\open-images-v7\\train\\labels\\masks\\7\n",
      "working on the  9th folder and folder path is :C:\\Users\\Tarek\\fiftyone\\open-images-v7\\train\\labels\\masks\\8\n",
      "working on the  10th folder and folder path is :C:\\Users\\Tarek\\fiftyone\\open-images-v7\\train\\labels\\masks\\9\n",
      "working on the  11th folder and folder path is :C:\\Users\\Tarek\\fiftyone\\open-images-v7\\train\\labels\\masks\\A\n",
      "working on the  12th folder and folder path is :C:\\Users\\Tarek\\fiftyone\\open-images-v7\\train\\labels\\masks\\B\n",
      "working on the  13th folder and folder path is :C:\\Users\\Tarek\\fiftyone\\open-images-v7\\train\\labels\\masks\\C\n",
      "working on the  14th folder and folder path is :C:\\Users\\Tarek\\fiftyone\\open-images-v7\\train\\labels\\masks\\D\n",
      "working on the  15th folder and folder path is :C:\\Users\\Tarek\\fiftyone\\open-images-v7\\train\\labels\\masks\\E\n",
      "working on the  16th folder and folder path is :C:\\Users\\Tarek\\fiftyone\\open-images-v7\\train\\labels\\masks\\F\n",
      "labels extracted successfully\n"
     ]
    }
   ],
   "source": [
    "label_folders = glob(os.path.join(ROOT_DIR,'labels','masks')+'/*')\n",
    "labels_paths = []\n",
    "i = 1\n",
    "for folder in tqdm(label_folders, desc='printing folders'):\n",
    "    print(f'working on the  {i}th folder and folder path is :{folder}')\n",
    "    labels = glob(folder+'/*')\n",
    "    labels_filtred = [path for path in labels if extract_id_from_image_path(path) in image_ids and 'm0k4j' in path ]\n",
    "    labels_paths.extend(labels_filtred)\n",
    "    i+=1\n",
    "print('labels extracted successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_id = [extract_id_from_image_path(path) for path in labels_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "# Count the occurrences of each element\n",
    "element_counts = Counter(labels_id)\n",
    "\n",
    "# Print the counts\n",
    "print(element_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "def copy_files(file_paths, destination_directory):\n",
    "    if not os.path.exists(destination_directory):\n",
    "        os.makedirs(destination_directory)\n",
    "        \n",
    "    for file_path in tqdm(file_paths, desc='copying files'):\n",
    "        if os.path.isfile(file_path):\n",
    "            try:\n",
    "                shutil.copy(file_path, destination_directory)\n",
    "                #print(f\"Copied {file_path} to {destination_directory}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to copy {file_path}: {e}\")\n",
    "        else:\n",
    "            print(f\"{file_path} does not exist or is not a file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**converting from binary masks to coco format**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "from pycococreator.pycococreatortools import pycococreatortools\n",
    "\n",
    "INFO = {\n",
    "    \"description\": \"Car_Tracking_2024\",\n",
    "    \"url\": \"None\",\n",
    "    \"version\": \"1.0\",\n",
    "    \"year\": 2024,\n",
    "    \"contributor\": \"Tarek\",\n",
    "    \"date_created\": datetime.datetime.now(datetime.UTC).isoformat(' ')\n",
    "}\n",
    "\n",
    "LICENSES = [{\"id\": 1, \"name\": \"Zewail\"}]\n",
    "CATEGORIES = [{'id': 1, 'name': 'm0k4j', 'supercategory': 'none'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_output = {\n",
    "    \"info\": INFO,\n",
    "    \"licenses\": LICENSES,\n",
    "    \"categories\": CATEGORIES,\n",
    "    \"images\": [],\n",
    "    \"annotations\": []\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = images_path\n",
    "annotation_files = labels_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of images is: 15003\n",
      "the number of masks is: 32532\n"
     ]
    }
   ],
   "source": [
    "print(f'the number of images is: {len(image_paths)}')\n",
    "print(f'the number of masks is: {len(annotation_files)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c1b40d6fb8e45bda13290f274212eaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "images preprocessing:   0%|          | 0/15003 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_id = 1\n",
    "for image_path in tqdm(image_paths, desc='images preprocessing'):\n",
    "    image = Image.open(image_path)\n",
    "    image_filename = image_path.split('\\\\')[-1]\n",
    "    image_info = pycococreatortools.create_image_info(image_id, os.path.basename(image_filename), image.size)\n",
    "    coco_output[\"images\"].append(image_info)\n",
    "    image_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "segmentation_id = 1\n",
    "for annotation_filepath in tqdm(annotation_files, desc='labels preprocessing'):\n",
    "    image_id = [f for f in coco_output['images'] if f['file_name'][0:16] == extract_id_from_image_path(annotation_filepath)][0]['id']\n",
    "    annotation_filename = annotation_filepath.split('\\\\')[-1]\n",
    "    class_id = [x['id'] for x in CATEGORIES if x['name'] in annotation_filename][0]\n",
    "    category_info = {'id': class_id, 'is_crowd': 'crowd' in annotation_filename}\n",
    "\n",
    "    # Load and check mask size\n",
    "    mask_image = Image.open(annotation_filepath).convert('1')\n",
    "    \n",
    "    # Resize mask if needed\n",
    "    if mask_image.size != (coco_output['images'][image_id-1]['width'], coco_output['images'][image_id-1]['height']):\n",
    "        #print(f\"Resizing mask from {mask_image.size} to {(coco_output['images'][image_id-1]['width'], coco_output['images'][image_id-1]['height'])}\")\n",
    "        mask_image = mask_image.resize((coco_output['images'][image_id-1]['width'], coco_output['images'][image_id-1]['height']), Image.NEAREST)\n",
    "    \n",
    "    binary_mask = np.asarray(mask_image).astype(np.uint8)\n",
    "\n",
    "    # Debugging: Print sizes to ensure they match\n",
    "    #print(f\"Processing image ID: {image_id}, Image size: {coco_output['images'][image_id-1]['width']}x{coco_output['images'][image_id-1]['height']}, Mask size: {mask_image.size}\")\n",
    "\n",
    "    annotation_info = pycococreatortools.create_annotation_info(segmentation_id, image_id, category_info, binary_mask, mask_image.size, tolerance=2)\n",
    "\n",
    "    if annotation_info is not None:\n",
    "        coco_output[\"annotations\"].append(annotation_info)\n",
    "        segmentation_id += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_output['categories'] = [{'id': 1, 'name': 'car', 'supercategory': 'none'}]\n",
    "\n",
    "import json\n",
    "with open('data.json', 'w') as output_json_file:\n",
    "    json.dump(coco_output, output_json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Specify the path to your JSON file\n",
    "json_file_path = 'test/data.json'\n",
    "\n",
    "# Open and load the JSON file\n",
    "with open(json_file_path, 'r') as file:\n",
    "    data = json.load(file)  # Save the JSON content to a Python variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From COCO to YOLO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import yaml\n",
    "def convert_to_yolo(input_images_path, input_json_path, output_labels_path):\n",
    "    # Open JSON file containing image annotations\n",
    "    f = open(input_json_path)\n",
    "    data = json.load(f)\n",
    "    f.close()\n",
    "\n",
    "    # Create directories for output images and labels\n",
    "    #os.makedirs(output_images_path, exist_ok=True)\n",
    "    os.makedirs(output_labels_path, exist_ok=True)\n",
    "\n",
    "    # List to store filenames\n",
    "    file_names = []\n",
    "    for filename in os.listdir(input_images_path):\n",
    "        if filename.endswith(\".jpg\"):\n",
    "            #source = os.path.join(input_images_path, filename)\n",
    "            #destination = os.path.join(output_images_path, filename)\n",
    "            #shutil.copy(source, destination)\n",
    "            file_names.append(filename)\n",
    "\n",
    "    # Function to get image annotations\n",
    "    def get_img_ann(image_id):\n",
    "        return [ann for ann in data['annotations'] if ann['image_id'] == image_id]\n",
    "\n",
    "    # Function to get image data\n",
    "    def get_img(filename):\n",
    "        return next((img for img in data['images'] if img['file_name'] == filename), None)\n",
    "\n",
    "    # Iterate through filenames and process each image\n",
    "    for filename in tqdm(file_names, desc='process each image'):\n",
    "        img = get_img(filename)\n",
    "        img_id = img['id']\n",
    "        img_w = img['width']\n",
    "        img_h = img['height']\n",
    "        img_ann = get_img_ann(img_id)\n",
    "\n",
    "        # Write normalized polygon data to a text file\n",
    "        if img_ann:\n",
    "            with open(os.path.join(output_labels_path, f\"{os.path.splitext(filename)[0]}.txt\"), \"a\") as file_object:\n",
    "                for ann in img_ann:\n",
    "                    current_category = ann['category_id'] - 1\n",
    "                    polygon = ann['segmentation'][0]\n",
    "                    normalized_polygon = [format(coord / img_w if i % 2 == 0 else coord / img_h, '.6f') for i, coord in enumerate(polygon)]\n",
    "                    file_object.write(f\"{current_category} \" + \" \".join(normalized_polygon) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea1131b9883341b988eccefbd3bc5c4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "process each image:   0%|          | 0/15003 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_image_paths = r'C:\\Users\\Tarek\\fiftyone\\open-images-v7\\train\\data'\n",
    "input_json_path = r'test\\data.json'\n",
    "output_labels_path = r'Labels'\n",
    "convert_to_yolo(input_image_paths, input_json_path, output_labels_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://youtu.be/NYeJvxe5nYw\n",
    "\"\"\"\n",
    "This code defines a function to display an image with its corresponding annotations. \n",
    "It reads an image and its associated annotation file in the YOLO v8 text format, \n",
    "then plots the image along with colored polygons representing the annotated regions. \n",
    "The polygons are drawn according to the coordinates provided in the annotation file, \n",
    "and colors are assigned based on the category ID.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import cv2\n",
    "\n",
    "def display_image_with_annotations(image_path, annotation_path, colors=None):\n",
    "    # Load image using OpenCV and convert it from BGR to RGB color space\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    img_h, img_w, _ = image.shape\n",
    "    \n",
    "    # Create a figure and axis to display the image\n",
    "    fig, ax = plt.subplots(1)\n",
    "    ax.imshow(image)\n",
    "    ax.axis('off')  # Turn off the axes\n",
    "\n",
    "    # Define a default color map if none is provided\n",
    "    if colors is None:\n",
    "        colors = plt.cm.get_cmap('tab10')\n",
    "\n",
    "    # Open the annotation file and process each line\n",
    "    with open(annotation_path, 'r') as file:\n",
    "        for line in file:\n",
    "            parts = line.strip().split()\n",
    "            category_id = int(parts[0])\n",
    "            # Choose color based on category ID, looping through color map if more than 10 categories\n",
    "            color = colors(category_id % 10)\n",
    "            # Extract normalized polygon coordinates and denormalize them\n",
    "            polygon = [float(coord) for coord in parts[1:]]\n",
    "            polygon = [coord * img_w if i % 2 == 0 else coord * img_h for i, coord in enumerate(polygon)]\n",
    "            # Reshape into (num_points, 2) array\n",
    "            polygon = [(polygon[i], polygon[i+1]) for i in range(0, len(polygon), 2)]\n",
    "            # Create a Polygon patch using the denormalized coordinates\n",
    "            patch = patches.Polygon(polygon, closed=True, edgecolor=color, fill=False)\n",
    "            # Add the patch to the plot to display the annotated region\n",
    "            ax.add_patch(patch)\n",
    "\n",
    "    plt.show()  # Display the image with annotations\n",
    "\n",
    "# Example usage with specified image and annotation paths\n",
    "image_path = \"C:\\Users\\Tarek\\fiftyone\\open-images-v7\\train\\data\\00cac7ea145fc734.jpg\"\n",
    "annotation_path = \"Labels\\00cac7ea145fc734.txt\"\n",
    "display_image_with_annotations(image_path, annotation_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Splittin Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15003\n",
      "15003\n"
     ]
    }
   ],
   "source": [
    "all_images_path = glob(r'C:\\Users\\Tarek\\fiftyone\\open-images-v7\\train\\data' +'/*')\n",
    "all_labels_path = glob(r'D:\\self-grinding\\deeplearning\\Project\\object-tracking\\Labels' +'/*')\n",
    "print(len(all_images_path))\n",
    "print(len(all_labels_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ids = [extract_id_from_image_path(path) for path in all_images_path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_ids, val_ids = train_test_split(all_ids, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_root_dir = r'C:\\Users\\Tarek\\fiftyone\\open-images-v7\\train\\data'\n",
    "labels_root_dir = r'Labels'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_paths = [os.path.join(images_root_dir,f'{id}.jpg') for id in train_ids]\n",
    "val_image_paths = [os.path.join(images_root_dir,f'{id}.jpg') for id in val_ids]\n",
    "train_label_paths = [os.path.join(labels_root_dir,f'{id}.txt') for id in train_ids]\n",
    "val_label_paths = [os.path.join(labels_root_dir,f'{id}.txt') for id in val_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69716b0007104becacfded52f13a564a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "copying files:   0%|          | 0/12002 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c51756f45794d9eb2a4592a03ea2fdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "copying files:   0%|          | 0/3001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a17d74391c7745a89a65773aff764f6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "copying files:   0%|          | 0/12002 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "237f1e225ac549bca27556ca6fefe902",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "copying files:   0%|          | 0/3001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "copy_files(train_image_paths, r'data\\images\\train')\n",
    "copy_files(val_image_paths, r'data\\images\\val' )\n",
    "copy_files(train_label_paths, r'data\\labels\\train')\n",
    "copy_files(val_label_paths, r'data\\labels\\val' )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
