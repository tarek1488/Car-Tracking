{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**importing packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "from glob import glob\n",
    "import os\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dawnloading data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "coco dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=27.29s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "from pycocotools.coco import COCO\n",
    "import requests\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Path to the COCO annotations file\n",
    "ann_file = r'C:\\Users\\Tarek\\fiftyone\\coco-2017\\raw\\instances_train2017.json'\n",
    "\n",
    "# Initialize COCO API\n",
    "coco = COCO(ann_file)\n",
    "\n",
    "# Specify the category you want (e.g., \"car\")\n",
    "cat_ids = coco.getCatIds(catNms=['car'])\n",
    "img_ids = coco.getImgIds(catIds=cat_ids)\n",
    "\n",
    "# Shuffle and select 5000 image IDs\n",
    "random.shuffle(img_ids)\n",
    "img_ids = img_ids[:600]\n",
    "\n",
    "# Load the relevant images\n",
    "images = coco.loadImgs(img_ids)\n",
    "\n",
    "# Create a directory to save the images\n",
    "output_dir = 'car_images_600'\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Specify the path to your JSON file\n",
    "json_file_path = 'cocoo.json'\n",
    "\n",
    "# Open and load the JSON file\n",
    "with open(json_file_path, 'r') as file:\n",
    "    data = json.load(file)  # Save the JSON content to a Python variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "downloaded_images = os.listdir('car_images_5000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [image for image in data if image['file_name'] not in downloaded_images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download images with progress bar\n",
    "for img in tqdm(images, desc=\"Downloading images\", unit=\"image\"):\n",
    "    img_data = requests.get(img['coco_url']).content\n",
    "    with open(os.path.join(output_dir, img['file_name']), 'wb') as handler:\n",
    "        handler.write(img_data)\n",
    "\n",
    "print(f\"Downloaded {len(images)} car images.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data == images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**!!!!!!check first the cocoo.json is the same as images when i run the cell**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mapping filenames to image IDs:   0%|          | 0/118287 [00:00<?, ?image/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mapping filenames to image IDs: 100%|██████████| 118287/118287 [00:01<00:00, 101967.16image/s]\n",
      "Gathering annotations: 100%|██████████| 2116/2116 [00:00<00:00, 423149.96annotation/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COCO-format JSON file created successfully.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pycocotools.coco import COCO\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Path to the COCO annotations file\n",
    "ann_file = r'C:\\Users\\Tarek\\fiftyone\\coco-2017\\raw\\instances_train2017.json'\n",
    "\n",
    "# Initialize COCO API\n",
    "#coco = COCO(ann_file)\n",
    "\n",
    "# Directory where images are saved\n",
    "output_dir = 'car_images_600'\n",
    "downloaded_files = os.listdir(output_dir)\n",
    "downloaded_file_names = [os.path.splitext(f)[0] for f in downloaded_files]\n",
    "\n",
    "# Map filenames to COCO image IDs and gather required data with progress bar\n",
    "img_ids = []\n",
    "images = []\n",
    "\n",
    "for img_id in tqdm(coco.getImgIds(), desc=\"Mapping filenames to image IDs\", unit=\"image\"):\n",
    "    img_info = coco.loadImgs(img_id)[0]\n",
    "    if os.path.splitext(img_info['file_name'])[0] in downloaded_file_names:\n",
    "        img_ids.append(img_id)\n",
    "        images.append({\n",
    "            \"id\": img_info['id'],\n",
    "            \"file_name\": img_info['file_name'],\n",
    "            \"width\": img_info['width'],\n",
    "            \"height\": img_info['height']\n",
    "        })\n",
    "\n",
    "# Gather annotations for these images with progress bar\n",
    "annotations = []\n",
    "cat_ids = coco.getCatIds(catNms=['car'])\n",
    "ann_ids = coco.getAnnIds(imgIds=img_ids, catIds=cat_ids, iscrowd=False)\n",
    "anns = coco.loadAnns(ann_ids)\n",
    "\n",
    "for ann in tqdm(anns, desc=\"Gathering annotations\", unit=\"annotation\"):\n",
    "    annotations.append({\n",
    "        \"id\": ann['id'],\n",
    "        \"image_id\": ann['image_id'],\n",
    "        \"category_id\": ann['category_id'],\n",
    "        \"segmentation\": ann['segmentation'],\n",
    "        \"bbox\": ann['bbox'],\n",
    "        \"area\": ann['area'],\n",
    "        \"iscrowd\": ann['iscrowd']\n",
    "    })\n",
    "\n",
    "# Define categories\n",
    "categories = [\n",
    "    {\n",
    "        \"id\": cat_ids[0],  # This should be the ID of the \"car\" class\n",
    "        \"name\": \"car\",\n",
    "        \"supercategory\": \"vehicle\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Combine all into the final JSON structure\n",
    "coco_format = {\n",
    "    \"images\": images,\n",
    "    \"annotations\": annotations,\n",
    "    \"categories\": categories\n",
    "}\n",
    "\n",
    "# Save the JSON file\n",
    "output_json = os.path.join(output_dir, 'car_annotations_coco600.json')\n",
    "with open(output_json, 'w') as f:\n",
    "    json.dump(coco_format, f)\n",
    "\n",
    "print(\"COCO-format JSON file created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load annotations for the selected images\n",
    "ann_ids = coco.getAnnIds(imgIds=img_ids, catIds=cat_ids, iscrowd=False)\n",
    "anns = coco.loadAnns(ann_ids)\n",
    "\n",
    "# Save annotations (optional)\n",
    "# You can save these annotations in a file or process them as needed\n",
    "ann_output_path = os.path.join(output_dir, 'car_annotations.json')\n",
    "with open(ann_output_path, 'w') as f:\n",
    "    import json\n",
    "    json.dump(anns, f)\n",
    "\n",
    "print(\"Annotations saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "open images dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = fo.zoo.load_zoo_dataset(\n",
    "    \"open-images\",\n",
    "    splits=\"train\",\n",
    "    label_types=\"segmentations\",\n",
    "    # max_samples=50,\n",
    ")\n",
    "\n",
    "print('data downloaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100% |█████████████| 15003/15003 [26.7m elapsed, 0s remaining, 7.3 samples/s]      \n"
     ]
    }
   ],
   "source": [
    "# The directory containing the dataset to import\n",
    "dataset_dir = r\"C:\\Users\\Tarek\\fiftyone\\open-images-v7\\train\"\n",
    "\n",
    "# The type of the dataset being imported\n",
    "dataset_type = fo.types.dataset_types.OpenImagesV7Dataset  # for example\n",
    "\n",
    "# Import the dataset\n",
    "dataset = fo.Dataset.from_dir(\n",
    "    dataset_dir=dataset_dir,\n",
    "    dataset_type=dataset_type,\n",
    "    label_types=[\"segmentations\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**getting labels for downloaded images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_id_from_image_path(path):\n",
    "    id = path.split('\\\\')[-1][0:16]\n",
    "    return id\n",
    "def extract_id_from_mask(path):\n",
    "    mask_id  = path.split('\\\\')[-1]\n",
    "    return mask_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = r'C:\\Users\\Tarek\\fiftyone\\open-images-v7\\train'\n",
    "images_path = glob(os.path.join(ROOT_DIR,'data')+'/*')\n",
    "#images_path = images_path[40:60]\n",
    "image_ids = [extract_id_from_image_path(path) for path in images_path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a6ee282596c42e491133704acad12d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "printing folders:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on the  1th folder and folder path is :C:\\Users\\Tarek\\fiftyone\\open-images-v7\\train\\labels\\masks\\0\n",
      "working on the  2th folder and folder path is :C:\\Users\\Tarek\\fiftyone\\open-images-v7\\train\\labels\\masks\\1\n",
      "working on the  3th folder and folder path is :C:\\Users\\Tarek\\fiftyone\\open-images-v7\\train\\labels\\masks\\2\n",
      "working on the  4th folder and folder path is :C:\\Users\\Tarek\\fiftyone\\open-images-v7\\train\\labels\\masks\\3\n",
      "working on the  5th folder and folder path is :C:\\Users\\Tarek\\fiftyone\\open-images-v7\\train\\labels\\masks\\4\n",
      "working on the  6th folder and folder path is :C:\\Users\\Tarek\\fiftyone\\open-images-v7\\train\\labels\\masks\\5\n",
      "working on the  7th folder and folder path is :C:\\Users\\Tarek\\fiftyone\\open-images-v7\\train\\labels\\masks\\6\n",
      "working on the  8th folder and folder path is :C:\\Users\\Tarek\\fiftyone\\open-images-v7\\train\\labels\\masks\\7\n",
      "working on the  9th folder and folder path is :C:\\Users\\Tarek\\fiftyone\\open-images-v7\\train\\labels\\masks\\8\n",
      "working on the  10th folder and folder path is :C:\\Users\\Tarek\\fiftyone\\open-images-v7\\train\\labels\\masks\\9\n",
      "working on the  11th folder and folder path is :C:\\Users\\Tarek\\fiftyone\\open-images-v7\\train\\labels\\masks\\A\n",
      "working on the  12th folder and folder path is :C:\\Users\\Tarek\\fiftyone\\open-images-v7\\train\\labels\\masks\\B\n",
      "working on the  13th folder and folder path is :C:\\Users\\Tarek\\fiftyone\\open-images-v7\\train\\labels\\masks\\C\n",
      "working on the  14th folder and folder path is :C:\\Users\\Tarek\\fiftyone\\open-images-v7\\train\\labels\\masks\\D\n",
      "working on the  15th folder and folder path is :C:\\Users\\Tarek\\fiftyone\\open-images-v7\\train\\labels\\masks\\E\n",
      "working on the  16th folder and folder path is :C:\\Users\\Tarek\\fiftyone\\open-images-v7\\train\\labels\\masks\\F\n",
      "labels extracted successfully\n"
     ]
    }
   ],
   "source": [
    "label_folders = glob(os.path.join(ROOT_DIR,'labels','masks')+'/*')\n",
    "labels_paths = []\n",
    "i = 1\n",
    "for folder in tqdm(label_folders, desc='printing folders'):\n",
    "    print(f'working on the  {i}th folder and folder path is :{folder}')\n",
    "    labels = glob(folder+'/*')\n",
    "    labels_filtred = [path for path in labels if extract_id_from_image_path(path) in image_ids and 'm0k4j' in path ]\n",
    "    labels_paths.extend(labels_filtred)\n",
    "    i+=1\n",
    "print('labels extracted successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_id = [extract_id_from_image_path(path) for path in labels_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "# Count the occurrences of each element\n",
    "element_counts = Counter(labels_id)\n",
    "\n",
    "# Print the counts\n",
    "print(element_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "def copy_files(file_paths, destination_directory):\n",
    "    if not os.path.exists(destination_directory):\n",
    "        os.makedirs(destination_directory)\n",
    "        \n",
    "    for file_path in tqdm(file_paths, desc='copying files'):\n",
    "        if os.path.isfile(file_path):\n",
    "            try:\n",
    "                shutil.copy(file_path, destination_directory)\n",
    "                #print(f\"Copied {file_path} to {destination_directory}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to copy {file_path}: {e}\")\n",
    "        else:\n",
    "            print(f\"{file_path} does not exist or is not a file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**converting from binary masks to coco format**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "from pycococreator.pycococreatortools import pycococreatortools\n",
    "\n",
    "INFO = {\n",
    "    \"description\": \"Car_Tracking_2024\",\n",
    "    \"url\": \"None\",\n",
    "    \"version\": \"1.0\",\n",
    "    \"year\": 2024,\n",
    "    \"contributor\": \"Tarek\",\n",
    "    \"date_created\": datetime.datetime.now(datetime.UTC).isoformat(' ')\n",
    "}\n",
    "\n",
    "LICENSES = [{\"id\": 1, \"name\": \"Zewail\"}]\n",
    "CATEGORIES = [{'id': 1, 'name': 'm0k4j', 'supercategory': 'none'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_output = {\n",
    "    \"info\": INFO,\n",
    "    \"licenses\": LICENSES,\n",
    "    \"categories\": CATEGORIES,\n",
    "    \"images\": [],\n",
    "    \"annotations\": []\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = images_path\n",
    "annotation_files = labels_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of images is: 15003\n",
      "the number of masks is: 32532\n"
     ]
    }
   ],
   "source": [
    "print(f'the number of images is: {len(image_paths)}')\n",
    "print(f'the number of masks is: {len(annotation_files)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c1b40d6fb8e45bda13290f274212eaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "images preprocessing:   0%|          | 0/15003 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_id = 1\n",
    "for image_path in tqdm(image_paths, desc='images preprocessing'):\n",
    "    image = Image.open(image_path)\n",
    "    image_filename = image_path.split('\\\\')[-1]\n",
    "    image_info = pycococreatortools.create_image_info(image_id, os.path.basename(image_filename), image.size)\n",
    "    coco_output[\"images\"].append(image_info)\n",
    "    image_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "segmentation_id = 1\n",
    "for annotation_filepath in tqdm(annotation_files, desc='labels preprocessing'):\n",
    "    image_id = [f for f in coco_output['images'] if f['file_name'][0:16] == extract_id_from_image_path(annotation_filepath)][0]['id']\n",
    "    annotation_filename = annotation_filepath.split('\\\\')[-1]\n",
    "    class_id = [x['id'] for x in CATEGORIES if x['name'] in annotation_filename][0]\n",
    "    category_info = {'id': class_id, 'is_crowd': 'crowd' in annotation_filename}\n",
    "\n",
    "    # Load and check mask size\n",
    "    mask_image = Image.open(annotation_filepath).convert('1')\n",
    "    \n",
    "    # Resize mask if needed\n",
    "    if mask_image.size != (coco_output['images'][image_id-1]['width'], coco_output['images'][image_id-1]['height']):\n",
    "        #print(f\"Resizing mask from {mask_image.size} to {(coco_output['images'][image_id-1]['width'], coco_output['images'][image_id-1]['height'])}\")\n",
    "        mask_image = mask_image.resize((coco_output['images'][image_id-1]['width'], coco_output['images'][image_id-1]['height']), Image.NEAREST)\n",
    "    \n",
    "    binary_mask = np.asarray(mask_image).astype(np.uint8)\n",
    "\n",
    "    # Debugging: Print sizes to ensure they match\n",
    "    #print(f\"Processing image ID: {image_id}, Image size: {coco_output['images'][image_id-1]['width']}x{coco_output['images'][image_id-1]['height']}, Mask size: {mask_image.size}\")\n",
    "\n",
    "    annotation_info = pycococreatortools.create_annotation_info(segmentation_id, image_id, category_info, binary_mask, mask_image.size, tolerance=2)\n",
    "\n",
    "    if annotation_info is not None:\n",
    "        coco_output[\"annotations\"].append(annotation_info)\n",
    "        segmentation_id += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_output['categories'] = [{'id': 1, 'name': 'car', 'supercategory': 'none'}]\n",
    "\n",
    "import json\n",
    "with open('data.json', 'w') as output_json_file:\n",
    "    json.dump(coco_output, output_json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Specify the path to your JSON file\n",
    "json_file_path = 'test/data.json'\n",
    "\n",
    "# Open and load the JSON file\n",
    "with open(json_file_path, 'r') as file:\n",
    "    data = json.load(file)  # Save the JSON content to a Python variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From COCO to YOLO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import yaml\n",
    "def convert_to_yolo(input_images_path, input_json_path, output_labels_path):\n",
    "    # Open JSON file containing image annotations\n",
    "    f = open(input_json_path)\n",
    "    data = json.load(f)\n",
    "    f.close()\n",
    "\n",
    "    # Create directories for output images and labels\n",
    "    #os.makedirs(output_images_path, exist_ok=True)\n",
    "    os.makedirs(output_labels_path, exist_ok=True)\n",
    "\n",
    "    # List to store filenames\n",
    "    file_names = []\n",
    "    for filename in os.listdir(input_images_path):\n",
    "        if filename.endswith(\".jpg\"):\n",
    "            #source = os.path.join(input_images_path, filename)\n",
    "            #destination = os.path.join(output_images_path, filename)\n",
    "            #shutil.copy(source, destination)\n",
    "            file_names.append(filename)\n",
    "\n",
    "    # Function to get image annotations\n",
    "    def get_img_ann(image_id):\n",
    "        return [ann for ann in data['annotations'] if ann['image_id'] == image_id]\n",
    "\n",
    "    # Function to get image data\n",
    "    def get_img(filename):\n",
    "        return next((img for img in data['images'] if img['file_name'] == filename), None)\n",
    "\n",
    "    # Iterate through filenames and process each image\n",
    "    for filename in tqdm(file_names, desc='process each image'):\n",
    "        img = get_img(filename)\n",
    "        img_id = img['id']\n",
    "        img_w = img['width']\n",
    "        img_h = img['height']\n",
    "        img_ann = get_img_ann(img_id)\n",
    "\n",
    "        # Write normalized polygon data to a text file\n",
    "        if img_ann:\n",
    "            with open(os.path.join(output_labels_path, f\"{os.path.splitext(filename)[0]}.txt\"), \"a\") as file_object:\n",
    "                for ann in img_ann:\n",
    "                    current_category = ann['category_id'] - 1\n",
    "                    polygon = ann['segmentation'][0]\n",
    "                    normalized_polygon = [format(coord / img_w if i % 2 == 0 else coord / img_h, '.6f') for i, coord in enumerate(polygon)]\n",
    "                    file_object.write(f\"{current_category} \" + \" \".join(normalized_polygon) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea1131b9883341b988eccefbd3bc5c4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "process each image:   0%|          | 0/15003 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_image_paths = r'C:\\Users\\Tarek\\fiftyone\\open-images-v7\\train\\data'\n",
    "input_json_path = r'test\\data.json'\n",
    "output_labels_path = r'Labels'\n",
    "convert_to_yolo(input_image_paths, input_json_path, output_labels_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Splittin Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15003\n",
      "15003\n"
     ]
    }
   ],
   "source": [
    "all_images_path = glob(r'C:\\Users\\Tarek\\fiftyone\\open-images-v7\\train\\data' +'/*')\n",
    "all_labels_path = glob(r'D:\\self-grinding\\deeplearning\\Project\\object-tracking\\Labels' +'/*')\n",
    "print(len(all_images_path))\n",
    "print(len(all_labels_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ids = [extract_id_from_image_path(path) for path in all_images_path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_ids, val_ids = train_test_split(all_ids, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_root_dir = r'C:\\Users\\Tarek\\fiftyone\\open-images-v7\\train\\data'\n",
    "labels_root_dir = r'Labels'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_paths = [os.path.join(images_root_dir,f'{id}.jpg') for id in train_ids]\n",
    "val_image_paths = [os.path.join(images_root_dir,f'{id}.jpg') for id in val_ids]\n",
    "train_label_paths = [os.path.join(labels_root_dir,f'{id}.txt') for id in train_ids]\n",
    "val_label_paths = [os.path.join(labels_root_dir,f'{id}.txt') for id in val_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69716b0007104becacfded52f13a564a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "copying files:   0%|          | 0/12002 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c51756f45794d9eb2a4592a03ea2fdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "copying files:   0%|          | 0/3001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a17d74391c7745a89a65773aff764f6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "copying files:   0%|          | 0/12002 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "237f1e225ac549bca27556ca6fefe902",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "copying files:   0%|          | 0/3001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "copy_files(train_image_paths, r'data\\images\\train')\n",
    "copy_files(val_image_paths, r'data\\images\\val' )\n",
    "copy_files(train_label_paths, r'data\\labels\\train')\n",
    "copy_files(val_label_paths, r'data\\labels\\val' )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
